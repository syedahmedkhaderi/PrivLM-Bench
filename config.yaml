data:
  dataset_config: wikitext-2-raw-v1
  dataset_name: wikitext
  max_seq_length: 512
  train_split: train
  validation_split: validation
dea:
  canary_repetitions:
  - 1
  - 5
  - 10
  - 20
  - 50
  - 100
  canary_types:
  - name
  - email
  - phone
  - ssn
  num_canaries_per_type: 10
  randomness_space_size: 1000000
model:
  cache_dir: ./cache
  model_name_or_path: gpt2
  name: gpt2
  tokenizer_name: gpt2
privacy:
  delta: 1.0e-05
  epsilon: 8.0
  max_grad_norm: 1.0
  use_dp: false
training:
  learning_rate: 5.0e-05
  logging_steps: 100
  num_train_epochs: 3
  output_dir: ./checkpoints
  per_device_eval_batch_size: 8
  per_device_train_batch_size: 4
  save_steps: 1000
  seed: 42
